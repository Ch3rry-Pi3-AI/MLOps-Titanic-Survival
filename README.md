# ğŸ“Š **Monitoring with Prometheus & Grafana**


This final stage integrates **Prometheus** and **Grafana** to enable real-time **monitoring**, **visualisation**, and **alerting** for your Flask inference app.  
You will now be able to track live metrics on:
- ğŸ§  **Prediction Count** â€” total number of predictions served  
- âš ï¸ **Drift Count** â€” total number of times data drift was detected  

Together, these complete your end-to-end MLOps pipeline:  
**Data âœ Model âœ Inference âœ Monitoring**



## ğŸ§© **Overview**

In this stage youâ€™ll:
1. Create the Prometheus and Docker Compose configuration files.  
2. Run both **Prometheus** and **Grafana** in the same Docker Compose network.  
3. Collect metrics automatically from the Flask app at `http://localhost:5000/metrics`.  
4. Visualise those metrics on a custom Grafana dashboard.



## âš™ï¸ **Step 1 â€” Create Required YAML Files**

Two configuration files are needed in the **project root**:

### ğŸ§¾ `prometheus.yml`
Defines Prometheus scrape settings (including your Flask app metrics endpoint).

### ğŸ§¾ `docker-compose.yml`
Bridges Prometheus and Grafana containers so they share the same network.

These two files allow Prometheus to collect the `/metrics` data exposed by your Flask app and Grafana to visualise it seamlessly.



## ğŸ§± **Step 2 â€” Run the Monitoring Stack**

In your terminal (from the project root):

```bash
docker compose up -d
````

This will pull and launch the Prometheus and Grafana Docker images.
Once running, check **Docker Desktop** â†’ **Containers** tab â€” you should see both running in the same stack:

![Docker Compose Stack](img/monitoring/compose_stack.png)



## ğŸ–¥ï¸ **Step 3 â€” Access Prometheus**

Visit:

ğŸ”— **[http://localhost:9090/](http://localhost:9090/)**

Youâ€™ll see the Prometheus dashboard interface:

![Prometheus UI](img/monitoring/prom_ui.png)

Prometheus will automatically scrape the `/metrics` endpoint of your Flask app every **15 seconds**.



## ğŸ“Š **Step 4 â€” Access Grafana**

Next, open:

ğŸ”— **[http://localhost:3000/](http://localhost:3000/)**

Youâ€™ll be greeted by the Grafana login screen:

![Grafana Login](img/monitoring/grafana_login.png)

Use:

```
Username: admin
Password: admin
```

After login, youâ€™ll enter the Grafana main dashboard:

![Grafana UI](img/monitoring/grafana_ui.png)



## âš™ï¸ **Step 5 â€” Ensure Flask App is Running**

Before metrics can be collected, your inference app must be live.

```bash
python app.py
```

This starts:

* Flask web server â†’ `http://localhost:5000/`
* Prometheus metrics endpoint â†’ `http://localhost:5000/metrics`

Visit the metrics endpoint:

![Flask Metrics Endpoint](img/monitoring/localhost_metrics.png)

Youâ€™ll see your counters defined in the Flask script:

```
# HELP prediction_count Number of prediction count
# TYPE prediction_count counter
prediction_count_total 0.0

# HELP drift_count Number of times data drift is detected
# TYPE drift_count counter
drift_count_total 0.0
```

These are scraped automatically by Prometheus at 15-second intervals.



## ğŸ”¢ **Step 6 â€” Generate Metrics via the Flask App**

Open the app at `http://localhost:5000/` and submit some predictions.

1ï¸âƒ£ **First prediction**

* Go back to `http://localhost:5000/metrics` â†’ refresh after 15â€“20 s
* Youâ€™ll now see:

  ```
  prediction_count_total 1.0
  drift_count_total 0.0
  ```

2ï¸âƒ£ **Trigger a drift**

* Use extreme inputs (e.g., Age = 150, Fare = 0)
* Wait 15â€“20 s and refresh again:

  ```
  prediction_count_total 2.0
  drift_count_total 1.0
  ```

Prometheus has now collected the updated metrics, and you can visualise them directly in Grafana.



## ğŸ“¡ **Step 7 â€” Link Prometheus to Grafana**

In Grafanaâ€™s left-hand toolbar:

1. Navigate to **Connections â†’ Data Sources**
2. Click **Add data source**
3. Select **Prometheus**
4. In the *Prometheus server URL* field, enter:

   ```
   http://prometheus:9090
   ```

   *(Use `prometheus`, not `localhost`, since both services run inside Docker Compose.)*

![Prometheusâ€“Grafana Link](img/monitoring/prom_grafana_link.png)

Scroll down and click **Save & Test**:

![Test Connection](img/monitoring/test_link.png)

You should see a confirmation message that Grafana successfully connected to Prometheus.



## ğŸ“ˆ **Step 8 â€” Create a Grafana Dashboard**

Now, letâ€™s visualise the metrics you just generated.

1. In Grafana, go to **Dashboards â†’ + New â†’ New Dashboard â†’ Add Visualization**
2. Choose **Prometheus** as the data source
3. From the metric dropdown, select **`prediction_count_total`**
4. Click **Run queries** â€” youâ€™ll see the live counter value

![Prediction Count Query](img/monitoring/query_1.png)

5. Now click **+ Add query**
6. Select **`drift_count_total`**
7. Click **Run queries** again â€” both metrics appear in the same graph

![Drift Count Query](img/monitoring/query_2.png)

Grafana now visualises:

* 3 âœ… Predictions served
* 2 âš ï¸ Drift detections observed

Your **monitoring pipeline** is officially live!



## ğŸ§± **Final Project Structure**

```text
mlops-titanic-survival-prediction/
â”œâ”€â”€ artifacts/
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ processed/
â”‚   â””â”€â”€ models/
â”‚       â””â”€â”€ random_forest_model.pkl
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ database_config.py
â”‚   â””â”€â”€ paths_config.py
â”œâ”€â”€ img/
â”‚   â””â”€â”€ monitoring/
â”‚       â”œâ”€â”€ compose_stack.png
â”‚       â”œâ”€â”€ prom_ui.png
â”‚       â”œâ”€â”€ grafana_login.png
â”‚       â”œâ”€â”€ grafana_ui.png
â”‚       â”œâ”€â”€ localhost_metrics.png
â”‚       â”œâ”€â”€ prom_grafana_link.png
â”‚       â”œâ”€â”€ test_link.png
â”‚       â”œâ”€â”€ query_1.png
â”‚       â””â”€â”€ query_2.png
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ log_YYYY-MM-DD.log
â”œâ”€â”€ notebook/
â”‚   â””â”€â”€ titanic.ipynb
â”œâ”€â”€ pipeline/
â”‚   â””â”€â”€ training_pipeline.py
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ custom_exception.py
â”‚   â”œâ”€â”€ logger.py
â”‚   â”œâ”€â”€ data_ingestion.py
â”‚   â”œâ”€â”€ feature_store.py
â”‚   â”œâ”€â”€ feature_processing.py
â”‚   â””â”€â”€ model_training.py
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html
â”œâ”€â”€ static/
â”‚   â””â”€â”€ style.css
â”œâ”€â”€ prometheus.yml                # Prometheus scrape config
â”œâ”€â”€ docker-compose.yml            # Compose stack bridging Prometheus + Grafana
â”œâ”€â”€ app.py                        # Flask inference + Prometheus exporter
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â””â”€â”€ README.md
```



## ğŸ§  **What You Achieved**

âœ… Real-time metric collection via **Prometheus**
âœ… Interactive visualisation in **Grafana**
âœ… Seamless bridge between **Flask inference** and **monitoring stack**
âœ… Reproducible setup using **Docker Compose**
âœ… Full end-to-end MLOps workflow â€” from ingestion to deployment to observability



## ğŸ¯ **Next Steps**

* ğŸ“¦ Integrate **Grafana alerts** for abnormal drift spikes
* â˜ï¸ Deploy the entire stack on **AWS EC2** or **GCP VM**
* ğŸ” Automate metric refreshes and dashboard provisioning via **Grafana JSON** exports

Congratulations â€” youâ€™ve built a **complete MLOps system** with continuous **training âœ inference âœ monitoring**.
