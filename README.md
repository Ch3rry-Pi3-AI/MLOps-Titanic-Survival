# ğŸŒ **Inference Stage â€” Flask Web App (MLOps Titanic Survival Prediction)**

![Titanic Survival Dashboard Demo](img/flask_app/titanic.gif)

This stage transforms your trained Random Forest model into a **fully interactive inference dashboard**, served via **Flask**.  
Users can enter passenger details, receive **real-time predictions**, and view **data drift detection results** in a single elegant interface.  
The app also exports **Prometheus metrics** for future monitoring and alerting via **Grafana**.


## ğŸ§  **Key Features**

* ğŸ§ **Passenger Input Form** â€” enter values for age, fare, class, sex, port of embarkation, etc.  
* ğŸ“Š **Live Model Prediction** â€” displays *SURVIVED* or *DID NOT SURVIVE* with probability estimates.  
* âš ï¸ **Data Drift Detection** â€” powered by **Alibi Detect (KSDrift)**, showing per-feature p-values and flagged drift indicators.  
* ğŸ§¾ **Human-Readable Summary** â€” contextualises predictions (e.g., â€œA Female aged 28 in Second Classâ€¦â€).  
* ğŸŒ™ **Night Mode Glass UI** â€” a responsive dark theme with glowing buttons and translucent panels.  
* ğŸ“ˆ **Prometheus Metrics Endpoint** â€” exposes `/metrics` for scraping model activity statistics:
  - `prediction_count` â€” total predictions served  
  - `drift_count` â€” total drift detections  
* ğŸ§© **Scalable Design** â€” easy to extend with additional routes, models, or input variables.

## âš™ï¸ **Run the Flask App**

From the project root:

```bash
python app.py
````

This launches:

* Flask app on **port 5000**
* Prometheus metrics endpoint on **port 8000**

Then open your browser at ğŸ‘‰ `http://localhost:5000`

## ğŸ’¡ **Dashboard Walkthrough**

The animated demo below illustrates:

* Submitting passenger details that yield both **SURVIVED** and **DID NOT SURVIVE** outcomes.
* A case where **data drift** is triggered and flagged in the Drift Detector panel.

![Titanic Survival GIF](img/flask_app/titanic.gif)

## ğŸ—‚ï¸ **Updated Project Structure**

```text
mlops-titanic-survival-prediction/
â”œâ”€â”€ artifacts/
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ processed/
â”‚   â””â”€â”€ models/
â”‚       â””â”€â”€ random_forest_model.pkl
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ database_config.py
â”‚   â””â”€â”€ paths_config.py
â”œâ”€â”€ img/
â”‚   â””â”€â”€ flask_app/
â”‚       â””â”€â”€ titanic.gif
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ log_YYYY-MM-DD.log
â”œâ”€â”€ notebook/
â”‚   â””â”€â”€ titanic.ipynb
â”œâ”€â”€ pipeline/
â”‚   â””â”€â”€ training_pipeline.py
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ custom_exception.py
â”‚   â”œâ”€â”€ logger.py
â”‚   â”œâ”€â”€ data_ingestion.py
â”‚   â”œâ”€â”€ feature_store.py
â”‚   â”œâ”€â”€ feature_processing.py
â”‚   â””â”€â”€ model_training.py
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html                # Flask UI template
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ style.css                 # Night Mode Glass UI stylesheet
â”‚   â””â”€â”€ background.jpg            # Optional background image
â”œâ”€â”€ app.py                        # Flask inference web app
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â””â”€â”€ README.md
```

## ğŸ§© **Integration Summary**

This stage bridges **model training â†’ real-time inference**.
It demonstrates the full loop of:

1. Loading trained model artefacts
2. Accepting user input
3. Computing predictions
4. Detecting data drift
5. Serving outputs through a modern UI

The result is an **end-to-end, production-style inference pipeline** with observability hooks in place.

## ğŸš€ **Next Stage â€” Monitoring with Prometheus & Grafana**

Next, youâ€™ll deploy **Prometheus** and **Grafana** to monitor:

* Model prediction volume (`prediction_count`)
* Drift detection frequency (`drift_count`)
* System health and response latency

This step adds real-time **monitoring**, **alerting**, and **dashboarding** capabilities â€” completing the MLOps lifecycle.